{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import sys\n",
    "sys.path.append('/home/reiichiro/ipython_notebooks/Project/files for cv')\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from myscorer import my_custom_scorer_neural\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.callbacks import ProgbarLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.8909911 ,  0.75005068,  0.7497068 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.8909911 ,  0.75005068,  0.7497068 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.8909911 ,  0.75005068,  0.7497068 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.88798993,  0.88168444,  0.88168444, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.88798993,  0.88168444,  0.88168444, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.88798993,  0.88168444,  0.88168444, ...,  0.        ,\n",
       "          0.        ,  0.        ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_features_matrix = joblib.load('Pickles/Condensed_Basic+Temporal+Recency/train.pkl')\n",
    "complete_features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = joblib.load('Pickles/labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indices, test_indices = joblib.load('Pickles/cv_indices')\n",
    "cv_iterable = [(train_indices, test_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_fn(no_hidden=14, hidden_activation='sigmoid', out_activation='sigmoid', \n",
    "             loss='mse', optimizer='rmsprop', random_state=0, \n",
    "             callbacks=[EarlyStopping(monitor='val_loss', patience=2)], \n",
    "             validation_split=0.2):\n",
    "    \n",
    "    np.random.seed(0)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(no_hidden, input_dim=28),\n",
    "        Activation(hidden_activation),\n",
    "        Dense(1),\n",
    "        Activation(out_activation),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasClassifier at 0x7f4709d6a210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KerasClassifier(build_fn)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'batch_size': [128], 'nb_epoch': [1, 2, 3], \n",
    "   'hidden_activation': ['relu', 'sigmoid'], 'optimizer': ['rmsprop', 'sgd']}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=cv_iterable, scoring=my_custom_scorer_neural, n_jobs=1, verbose=10, refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 12 candidates, totalling 12 fits\n",
      "[CV] hidden_activation=relu, optimizer=rmsprop, nb_epoch=1, batch_size=128 \n",
      "Epoch 1/1\n",
      "7996914/7996914 [==============================] - 55s - loss: 0.0977    \n",
      "482432/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=relu, optimizer=rmsprop, nb_epoch=1, batch_size=128, score=-0.296573 - 2.2min\n",
      "[CV] hidden_activation=relu, optimizer=sgd, nb_epoch=1, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7996914/7996914 [==============================] - 100s - loss: 0.1115   \n",
      "481536/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=relu, optimizer=sgd, nb_epoch=1, batch_size=128, score=-0.310359 - 3.6min\n",
      "[CV] hidden_activation=relu, optimizer=rmsprop, nb_epoch=2, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7996914/7996914 [==============================] - 106s - loss: 0.0977   \n",
      "Epoch 2/2\n",
      "7996914/7996914 [==============================] - 54s - loss: 0.0953    \n",
      "487006/487006 [==============================] - 0s     \n",
      "[CV]  hidden_activation=relu, optimizer=rmsprop, nb_epoch=2, batch_size=128, score=-0.297961 - 4.8min\n",
      "[CV] hidden_activation=relu, optimizer=sgd, nb_epoch=2, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 10.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7996914/7996914 [==============================] - 111s - loss: 0.1115   \n",
      "Epoch 2/2\n",
      "7996914/7996914 [==============================] - 46s - loss: 0.1042    \n",
      "480256/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=relu, optimizer=sgd, nb_epoch=2, batch_size=128, score=-0.305288 - 4.5min\n",
      "[CV] hidden_activation=relu, optimizer=rmsprop, nb_epoch=3, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 15.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7996914/7996914 [==============================] - 123s - loss: 0.0977   \n",
      "Epoch 2/3\n",
      "7996914/7996914 [==============================] - 59s - loss: 0.0953    \n",
      "Epoch 3/3\n",
      "7996914/7996914 [==============================] - 58s - loss: 0.0948    \n",
      "484992/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=relu, optimizer=rmsprop, nb_epoch=3, batch_size=128, score=-0.299583 - 5.8min\n",
      "[CV] hidden_activation=relu, optimizer=sgd, nb_epoch=3, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 20.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7996914/7996914 [==============================] - 74s - loss: 0.1115    \n",
      "Epoch 2/3\n",
      "7996914/7996914 [==============================] - 47s - loss: 0.1042    \n",
      "Epoch 3/3\n",
      "7996914/7996914 [==============================] - 46s - loss: 0.1026    \n",
      "486400/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=relu, optimizer=sgd, nb_epoch=3, batch_size=128, score=-0.305114 - 6.9min\n",
      "[CV] hidden_activation=sigmoid, optimizer=rmsprop, nb_epoch=1, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 27.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7996914/7996914 [==============================] - 120s - loss: 0.0970   \n",
      "487006/487006 [==============================] - 0s     \n",
      "[CV]  hidden_activation=sigmoid, optimizer=rmsprop, nb_epoch=1, batch_size=128, score=-0.296181 - 3.7min\n",
      "[CV] hidden_activation=sigmoid, optimizer=sgd, nb_epoch=1, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 31.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7996914/7996914 [==============================] - 115s - loss: 0.1121   \n",
      "487006/487006 [==============================] - 0s     \n",
      "[CV]  hidden_activation=sigmoid, optimizer=sgd, nb_epoch=1, batch_size=128, score=-0.312501 - 3.4min\n",
      "[CV] hidden_activation=sigmoid, optimizer=rmsprop, nb_epoch=2, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 34.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7996914/7996914 [==============================] - 116s - loss: 0.0970   \n",
      "Epoch 2/2\n",
      "7996914/7996914 [==============================] - 53s - loss: 0.0949    \n",
      "484992/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=sigmoid, optimizer=rmsprop, nb_epoch=2, batch_size=128, score=-0.297519 - 4.6min\n",
      "[CV] hidden_activation=sigmoid, optimizer=sgd, nb_epoch=2, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 39.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7996914/7996914 [==============================] - 95s - loss: 0.1121    \n",
      "Epoch 2/2\n",
      "7996914/7996914 [==============================] - 45s - loss: 0.1047    \n",
      "487006/487006 [==============================] - 1s     \n",
      "[CV]  hidden_activation=sigmoid, optimizer=sgd, nb_epoch=2, batch_size=128, score=-0.307883 - 6.3min\n",
      "[CV] hidden_activation=sigmoid, optimizer=rmsprop, nb_epoch=3, batch_size=128 \n",
      "Epoch 1/3\n",
      "7996914/7996914 [==============================] - 111s - loss: 0.0970   \n",
      "Epoch 2/3\n",
      "7996914/7996914 [==============================] - 49s - loss: 0.0949    \n",
      "Epoch 3/3\n",
      "7996914/7996914 [==============================] - 50s - loss: 0.0945    \n",
      "486144/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=sigmoid, optimizer=rmsprop, nb_epoch=3, batch_size=128, score=-0.296831 - 7.4min\n",
      "[CV] hidden_activation=sigmoid, optimizer=sgd, nb_epoch=3, batch_size=128 \n",
      "Epoch 1/3\n",
      "7996914/7996914 [==============================] - 140s - loss: 0.1121   \n",
      "Epoch 2/3\n",
      "7996914/7996914 [==============================] - 45s - loss: 0.1047    \n",
      "Epoch 3/3\n",
      "7996914/7996914 [==============================] - 46s - loss: 0.1025    \n",
      "487006/487006 [==============================] - 0s     \n",
      "[CV]  hidden_activation=sigmoid, optimizer=sgd, nb_epoch=3, batch_size=128, score=-0.305802 - 6.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 59.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[(array([      0,       1, ..., 8483911, 8483919], dtype=int32), array([     31,      32, ..., 8483917, 8483918], dtype=int32))],\n",
       "       error_score='raise',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f784c479b50>,\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'nb_epoch': [1, 2, 3], 'optimizer': ['rmsprop', 'sgd'], 'hidden_activation': ['relu', 'sigmoid'], 'batch_size': [128]}],\n",
       "       pre_dispatch='2*n_jobs', refit=False,\n",
       "       scoring=<function my_custom_scorer_neural at 0x7f78222809b0>,\n",
       "       verbose=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(complete_features_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -0.29657, std: 0.00000, params: {'hidden_activation': 'relu', 'optimizer': 'rmsprop', 'nb_epoch': 1, 'batch_size': 128},\n",
       " mean: -0.31036, std: 0.00000, params: {'hidden_activation': 'relu', 'optimizer': 'sgd', 'nb_epoch': 1, 'batch_size': 128},\n",
       " mean: -0.29796, std: 0.00000, params: {'hidden_activation': 'relu', 'optimizer': 'rmsprop', 'nb_epoch': 2, 'batch_size': 128},\n",
       " mean: -0.30529, std: 0.00000, params: {'hidden_activation': 'relu', 'optimizer': 'sgd', 'nb_epoch': 2, 'batch_size': 128},\n",
       " mean: -0.29958, std: 0.00000, params: {'hidden_activation': 'relu', 'optimizer': 'rmsprop', 'nb_epoch': 3, 'batch_size': 128},\n",
       " mean: -0.30511, std: 0.00000, params: {'hidden_activation': 'relu', 'optimizer': 'sgd', 'nb_epoch': 3, 'batch_size': 128},\n",
       " mean: -0.29618, std: 0.00000, params: {'hidden_activation': 'sigmoid', 'optimizer': 'rmsprop', 'nb_epoch': 1, 'batch_size': 128},\n",
       " mean: -0.31250, std: 0.00000, params: {'hidden_activation': 'sigmoid', 'optimizer': 'sgd', 'nb_epoch': 1, 'batch_size': 128},\n",
       " mean: -0.29752, std: 0.00000, params: {'hidden_activation': 'sigmoid', 'optimizer': 'rmsprop', 'nb_epoch': 2, 'batch_size': 128},\n",
       " mean: -0.30788, std: 0.00000, params: {'hidden_activation': 'sigmoid', 'optimizer': 'sgd', 'nb_epoch': 2, 'batch_size': 128},\n",
       " mean: -0.29683, std: 0.00000, params: {'hidden_activation': 'sigmoid', 'optimizer': 'rmsprop', 'nb_epoch': 3, 'batch_size': 128},\n",
       " mean: -0.30580, std: 0.00000, params: {'hidden_activation': 'sigmoid', 'optimizer': 'sgd', 'nb_epoch': 3, 'batch_size': 128}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/1.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_search, 'Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/1.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more grids, same xcept for adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'batch_size': [128], 'nb_epoch': [1, 2, 3], \n",
    "   'hidden_activation': ['relu', 'sigmoid'], 'optimizer': ['adam']}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=cv_iterable, scoring=my_custom_scorer_neural, n_jobs=1, verbose=10, refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 6 candidates, totalling 6 fits\n",
      "[CV] hidden_activation=relu, optimizer=adam, nb_epoch=1, batch_size=128 \n",
      "Epoch 1/1\n",
      "7996914/7996914 [==============================] - 127s - loss: 0.0974   \n",
      "482432/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=relu, optimizer=adam, nb_epoch=1, batch_size=128, score=-0.299532 - 4.3min\n",
      "[CV] hidden_activation=relu, optimizer=adam, nb_epoch=2, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7996914/7996914 [==============================] - 143s - loss: 0.0974   \n",
      "Epoch 2/2\n",
      "7996914/7996914 [==============================] - 56s - loss: 0.0948    \n",
      "480000/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=relu, optimizer=adam, nb_epoch=2, batch_size=128, score=-0.294983 - 5.9min\n",
      "[CV] hidden_activation=relu, optimizer=adam, nb_epoch=3, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 10.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7996914/7996914 [==============================] - 156s - loss: 0.0974   \n",
      "Epoch 2/3\n",
      "7996914/7996914 [==============================] - 58s - loss: 0.0948    \n",
      "Epoch 3/3\n",
      "7996914/7996914 [==============================] - 54s - loss: 0.0944    \n",
      "482944/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=relu, optimizer=adam, nb_epoch=3, batch_size=128, score=-0.294372 - 6.7min\n",
      "[CV] hidden_activation=sigmoid, optimizer=adam, nb_epoch=1, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 16.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "7996914/7996914 [==============================] - 96s - loss: 0.0972    \n",
      "486272/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=sigmoid, optimizer=adam, nb_epoch=1, batch_size=128, score=-0.297498 - 7.1min\n",
      "[CV] hidden_activation=sigmoid, optimizer=adam, nb_epoch=2, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 24.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7996914/7996914 [==============================] - 132s - loss: 0.0972   \n",
      "Epoch 2/2\n",
      "7996914/7996914 [==============================] - 60s - loss: 0.0947    \n",
      "483840/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=sigmoid, optimizer=adam, nb_epoch=2, batch_size=128, score=-0.294601 - 8.9min\n",
      "[CV] hidden_activation=sigmoid, optimizer=adam, nb_epoch=3, batch_size=128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 33.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7996914/7996914 [==============================] - 112s - loss: 0.0972   \n",
      "Epoch 2/3\n",
      "7996914/7996914 [==============================] - 53s - loss: 0.0947    \n",
      "Epoch 3/3\n",
      "7996914/7996914 [==============================] - 55s - loss: 0.0943    \n",
      "482560/487006 [============================>.] - ETA: 0s[CV]  hidden_activation=sigmoid, optimizer=adam, nb_epoch=3, batch_size=128, score=-0.294223 - 8.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 41.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 41.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[(array([      0,       1, ..., 8483911, 8483919], dtype=int32), array([     31,      32, ..., 8483917, 8483918], dtype=int32))],\n",
       "       error_score='raise',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f784c479b50>,\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'nb_epoch': [1, 2, 3], 'optimizer': ['adam'], 'hidden_activation': ['relu', 'sigmoid'], 'batch_size': [128]}],\n",
       "       pre_dispatch='2*n_jobs', refit=False,\n",
       "       scoring=<function my_custom_scorer_neural at 0x7f78222809b0>,\n",
       "       verbose=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(complete_features_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -0.29953, std: 0.00000, params: {'hidden_activation': 'relu', 'optimizer': 'adam', 'nb_epoch': 1, 'batch_size': 128},\n",
       " mean: -0.29498, std: 0.00000, params: {'hidden_activation': 'relu', 'optimizer': 'adam', 'nb_epoch': 2, 'batch_size': 128},\n",
       " mean: -0.29437, std: 0.00000, params: {'hidden_activation': 'relu', 'optimizer': 'adam', 'nb_epoch': 3, 'batch_size': 128},\n",
       " mean: -0.29750, std: 0.00000, params: {'hidden_activation': 'sigmoid', 'optimizer': 'adam', 'nb_epoch': 1, 'batch_size': 128},\n",
       " mean: -0.29460, std: 0.00000, params: {'hidden_activation': 'sigmoid', 'optimizer': 'adam', 'nb_epoch': 2, 'batch_size': 128},\n",
       " mean: -0.29422, std: 0.00000, params: {'hidden_activation': 'sigmoid', 'optimizer': 'adam', 'nb_epoch': 3, 'batch_size': 128}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/2.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_search, 'Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/2.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search incorporating early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'batch_size': [128, 256], 'nb_epoch': [10], \n",
    "   'hidden_activation': ['relu', 'sigmoid'], \n",
    "   'optimizer': ['rmsprop', 'sgd', 'adam'], 'callbacks': [[EarlyStopping(monitor='val_loss', patience=2)]], \n",
    "   'validation_split': [0.2]}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=cv_iterable, scoring=my_custom_scorer_neural, n_jobs=1, verbose=10, refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 12 candidates, totalling 12 fits\n",
      "[CV] optimizer=rmsprop, hidden_activation=relu, batch_size=128, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f47266ebc50>], validation_split=0.2, nb_epoch=10 \n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 65s - loss: 0.0985 - val_loss: 0.0945\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0957 - val_loss: 0.0935\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0952 - val_loss: 0.0934\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 47s - loss: 0.0949 - val_loss: 0.0933\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0947 - val_loss: 0.0933\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0944 - val_loss: 0.0928\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0943 - val_loss: 0.0927\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0942 - val_loss: 0.0932\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0942 - val_loss: 0.0929\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0941 - val_loss: 0.0927\n",
      "479872/487006 [============================>.] - ETA: 0s[CV]  optimizer=rmsprop, hidden_activation=relu, batch_size=128, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f47266ebc50>], validation_split=0.2, nb_epoch=10, score=-0.293091 - 9.9min\n",
      "[CV] optimizer=sgd, hidden_activation=relu, batch_size=128, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f47266ebc50>], validation_split=0.2, nb_epoch=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  9.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 100s - loss: 0.1130 - val_loss: 0.1023\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.1051 - val_loss: 0.1100\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.1035 - val_loss: 0.1029\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.1025 - val_loss: 0.0985\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.1015 - val_loss: 0.0991\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.1010 - val_loss: 0.0985\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 37s - loss: 0.1004 - val_loss: 0.0968\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.0999 - val_loss: 0.0988\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0991 - val_loss: 0.0958\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0978 - val_loss: 0.0954\n",
      "481536/487006 [============================>.] - ETA: 0s[CV]  optimizer=sgd, hidden_activation=relu, batch_size=128, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f47266ebc50>], validation_split=0.2, nb_epoch=10, score=-0.298274 -11.9min\n",
      "[CV] optimizer=adam, hidden_activation=relu, batch_size=128, callbacks=[<keras.callbacks.EarlyStopping object at 0x7f47266ebc50>], validation_split=0.2, nb_epoch=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 21.8min remaining:    0.0s\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-703ef208099d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_features_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m                 for train, test in cv)\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1607\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_safe_split\u001b[0;34m(estimator, X, y, indices, train_indices)\u001b[0m\n\u001b[1;32m   1672\u001b[0m                 \u001b[0mX_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m             \u001b[0mX_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/__init__.pyc\u001b[0m in \u001b[0;36msafe_indexing\u001b[0;34m(X, indices)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search.fit(complete_features_matrix, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Grid search\" for my low memory laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'batch_size': [128, 256], 'nb_epoch': [10], \n",
    "   'hidden_activation': ['relu', 'sigmoid'], \n",
    "   'optimizer': ['rmsprop', 'sgd', 'adam'], 'callbacks': [[EarlyStopping(monitor='val_loss', patience=2)]], \n",
    "   'validation_split': [0.2]}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7996914, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = joblib.load('Pickles/Condensed_Basic+Temporal+Recency/X_train.pkl')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487006, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = joblib.load('Pickles/Condensed_Basic+Temporal+Recency/X_val.pkl')\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7996914,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = joblib.load('Pickles/labels_train.pkl')\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487006,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = joblib.load('Pickles/labels_val.pkl')\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_fn(no_hidden=14, hidden_activation='sigmoid', out_activation='sigmoid', \n",
    "             loss='mse', optimizer='rmsprop', random_state=0):\n",
    "    \n",
    "    np.random.seed(0)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(no_hidden, input_dim=28),\n",
    "        Activation(hidden_activation),\n",
    "        Dense(1),\n",
    "        Activation(out_activation),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting CV for 128 10 relu rmsprop\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 47s - loss: 0.0985 - val_loss: 0.0945\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0957 - val_loss: 0.0935\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.0952 - val_loss: 0.0934\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0949 - val_loss: 0.0933\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0947 - val_loss: 0.0933\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0944 - val_loss: 0.0928\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0943 - val_loss: 0.0927\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0942 - val_loss: 0.0932\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0942 - val_loss: 0.0929\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0941 - val_loss: 0.0927\n",
      "479744/487006 [============================>.] - ETA: 0s-0.29309132644\n",
      "\n",
      "\n",
      "Starting CV for 128 10 relu sgd\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.1130 - val_loss: 0.1023\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 36s - loss: 0.1051 - val_loss: 0.1100\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.1035 - val_loss: 0.1029\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.1025 - val_loss: 0.0985\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.1015 - val_loss: 0.0991\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.1010 - val_loss: 0.0985\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.1004 - val_loss: 0.0968\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 37s - loss: 0.0999 - val_loss: 0.0988\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0991 - val_loss: 0.0958\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0978 - val_loss: 0.0954\n",
      "484736/487006 [============================>.] - ETA: 0s-0.298273978581\n",
      "\n",
      "\n",
      "Starting CV for 128 10 relu adam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0980 - val_loss: 0.0942\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0951 - val_loss: 0.0932\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0948 - val_loss: 0.0938\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0946 - val_loss: 0.0935\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0945 - val_loss: 0.0930\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0944 - val_loss: 0.0928\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 46s - loss: 0.0943 - val_loss: 0.0926\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0940 - val_loss: 0.0928\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0939 - val_loss: 0.0928\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 47s - loss: 0.0938 - val_loss: 0.0925\n",
      "480512/487006 [============================>.] - ETA: 0s-0.293319542134\n",
      "\n",
      "\n",
      "Starting CV for 128 10 sigmoid rmsprop\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0977 - val_loss: 0.0945\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0953 - val_loss: 0.0936\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0949 - val_loss: 0.0932\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0947 - val_loss: 0.0932\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.0945 - val_loss: 0.0932\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.0943 - val_loss: 0.0927\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.0942 - val_loss: 0.0927\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0940 - val_loss: 0.0936\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0939 - val_loss: 0.0924\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0938 - val_loss: 0.0925\n",
      "481536/487006 [============================>.] - ETA: 0s-0.293017273122\n",
      "\n",
      "\n",
      "Starting CV for 128 10 sigmoid sgd\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 47s - loss: 0.1136 - val_loss: 0.1065\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 46s - loss: 0.1059 - val_loss: 0.1033\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 47s - loss: 0.1036 - val_loss: 0.1014\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.1022 - val_loss: 0.1004\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.1011 - val_loss: 0.0997\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.1003 - val_loss: 0.0983\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0996 - val_loss: 0.0975\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0991 - val_loss: 0.0987\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.0987 - val_loss: 0.0967\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0983 - val_loss: 0.0962\n",
      "481280/487006 [============================>.] - ETA: 0s-0.299482916146\n",
      "\n",
      "\n",
      "Starting CV for 128 10 sigmoid adam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0979 - val_loss: 0.0947\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0951 - val_loss: 0.0935\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0947 - val_loss: 0.0932\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 50s - loss: 0.0944 - val_loss: 0.0931\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0942 - val_loss: 0.0926\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 50s - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 50s - loss: 0.0938 - val_loss: 0.0924\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0937 - val_loss: 0.0923\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0936 - val_loss: 0.0923\n",
      "484992/487006 [============================>.] - ETA: 0s-0.292660220849\n",
      "\n",
      "\n",
      "Starting CV for 256 10 relu rmsprop\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0997 - val_loss: 0.0949\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0959 - val_loss: 0.0944\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.0954 - val_loss: 0.0943\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.0952 - val_loss: 0.0934\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 31s - loss: 0.0950 - val_loss: 0.0938\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.0948 - val_loss: 0.0939\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 31s - loss: 0.0945 - val_loss: 0.0929\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.0944 - val_loss: 0.0940\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0943 - val_loss: 0.0927\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0942 - val_loss: 0.0928\n",
      "485632/487006 [============================>.] - ETA: 0s-0.29345745106\n",
      "\n",
      "\n",
      "Starting CV for 256 10 relu sgd\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1168 - val_loss: 0.1102\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1071 - val_loss: 0.1044\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1051 - val_loss: 0.1004\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 28s - loss: 0.1040 - val_loss: 0.1003\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 28s - loss: 0.1033 - val_loss: 0.1002\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 28s - loss: 0.1025 - val_loss: 0.1006\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1021 - val_loss: 0.1009\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1017 - val_loss: 0.1026\n",
      "483328/487006 [============================>.] - ETA: 0s-0.310176724656\n",
      "\n",
      "\n",
      "Starting CV for 256 10 relu adam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.0998 - val_loss: 0.0950\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.0952 - val_loss: 0.0933\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.0948 - val_loss: 0.0930\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0946 - val_loss: 0.0934\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0945 - val_loss: 0.0929\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 31s - loss: 0.0944 - val_loss: 0.0928\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.0944 - val_loss: 0.0930\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0943 - val_loss: 0.0930\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.0943 - val_loss: 0.0929\n",
      "475904/487006 [============================>.] - ETA: 0s-0.294679649654\n",
      "\n",
      "\n",
      "Starting CV for 256 10 sigmoid rmsprop\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 35s - loss: 0.0986 - val_loss: 0.0949\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0954 - val_loss: 0.0944\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0950 - val_loss: 0.0936\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0948 - val_loss: 0.0935\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0946 - val_loss: 0.0936\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 36s - loss: 0.0945 - val_loss: 0.0932\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0943 - val_loss: 0.0929\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0942 - val_loss: 0.0943\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0941 - val_loss: 0.0927\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0941 - val_loss: 0.0928\n",
      "484864/487006 [============================>.] - ETA: 0s-0.293348586813\n",
      "\n",
      "\n",
      "Starting CV for 256 10 sigmoid sgd\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1175 - val_loss: 0.1107\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1096 - val_loss: 0.1069\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 28s - loss: 0.1066 - val_loss: 0.1044\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 28s - loss: 0.1049 - val_loss: 0.1032\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1038 - val_loss: 0.1024\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1030 - val_loss: 0.1014\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1023 - val_loss: 0.1005\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 28s - loss: 0.1016 - val_loss: 0.1010\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1011 - val_loss: 0.0995\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 29s - loss: 0.1005 - val_loss: 0.0987\n",
      "479744/487006 [============================>.] - ETA: 0s-0.302752395712\n",
      "\n",
      "\n",
      "Starting CV for 256 10 sigmoid adam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0996 - val_loss: 0.0945\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0952 - val_loss: 0.0946\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0949 - val_loss: 0.0935\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0946 - val_loss: 0.0933\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0944 - val_loss: 0.0929\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0942 - val_loss: 0.0927\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0941 - val_loss: 0.0926\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 35s - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0938 - val_loss: 0.0926\n",
      "481536/487006 [============================>.] - ETA: 0s-0.293437430927\n"
     ]
    }
   ],
   "source": [
    "grid_scores = {}\n",
    "for batch_size in param_grid[0]['batch_size']:\n",
    "    for nb_epoch in param_grid[0]['nb_epoch']:\n",
    "        for hidden_activation in param_grid[0]['hidden_activation']:\n",
    "            for optimizer in param_grid[0]['optimizer']:\n",
    "                key = \" \".join([str(batch_size), str(nb_epoch), str(hidden_activation), str(optimizer)])\n",
    "                print(\"\\n\\nStarting CV for \" + key)\n",
    "                clf = KerasClassifier(build_fn, batch_size=batch_size, \n",
    "                                      nb_epoch=nb_epoch, hidden_activation=hidden_activation, \n",
    "                                      optimizer=optimizer, \n",
    "                                      callbacks=[EarlyStopping(monitor='val_loss', patience=2)], \n",
    "                                      validation_split=0.2)\n",
    "                clf.fit(X_train, y_train)\n",
    "                rmse = my_custom_scorer_neural(clf, X_val, y_val)\n",
    "                grid_scores[key] = rmse\n",
    "                print rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'128 10 relu adam': -0.29331954213373795,\n",
       " '128 10 relu rmsprop': -0.29309132643991853,\n",
       " '128 10 relu sgd': -0.29827397858100779,\n",
       " '128 10 sigmoid adam': -0.29266022084908949,\n",
       " '128 10 sigmoid rmsprop': -0.2930172731217085,\n",
       " '128 10 sigmoid sgd': -0.29948291614577865,\n",
       " '256 10 relu adam': -0.29467964965361709,\n",
       " '256 10 relu rmsprop': -0.29345745105973514,\n",
       " '256 10 relu sgd': -0.31017672465606788,\n",
       " '256 10 sigmoid adam': -0.29343743092671648,\n",
       " '256 10 sigmoid rmsprop': -0.29334858681252246,\n",
       " '256 10 sigmoid sgd': -0.30275239571168105}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/3(dict).pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_scores, 'Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/3(dict).pkl', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low memory grid search experimenting with no hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'batch_size': [128], 'nb_epoch': [10], \n",
    "   'hidden_activation': ['relu', 'sigmoid'], \n",
    "   'optimizer': ['rmsprop', 'sgd', 'adam'], 'callbacks': [[EarlyStopping(monitor='val_loss', patience=2)]], \n",
    "   'validation_split': [0.2], 'no_hidden': [7, 18]}\n",
    " ]\n",
    "\n",
    "def build_fn(no_hidden=14, hidden_activation='sigmoid', out_activation='sigmoid', \n",
    "             loss='mse', optimizer='rmsprop', random_state=0):\n",
    "    \n",
    "    np.random.seed(0)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(no_hidden, input_dim=28),\n",
    "        Activation(hidden_activation),\n",
    "        Dense(1),\n",
    "        Activation(out_activation),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting CV for 7 128 10 relu rmsprop\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0991 - val_loss: 0.0945\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 36s - loss: 0.0958 - val_loss: 0.0946\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 36s - loss: 0.0955 - val_loss: 0.0941\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0954 - val_loss: 0.0938\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0952 - val_loss: 0.0936\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0951 - val_loss: 0.0954\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0951 - val_loss: 0.0940\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0950 - val_loss: 0.0936\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 33s - loss: 0.0950 - val_loss: 0.0938\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0950 - val_loss: 0.0937\n",
      "486016/487006 [============================>.] - ETA: 0s-0.29474118465\n",
      "\n",
      "\n",
      "Starting CV for 7 128 10 relu sgd\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.1149 - val_loss: 0.1070\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 31s - loss: 0.1082 - val_loss: 0.1032\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 31s - loss: 0.1056 - val_loss: 0.1009\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 32s - loss: 0.1038 - val_loss: 0.1003\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.1026 - val_loss: 0.0989\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 35s - loss: 0.1016 - val_loss: 0.0988\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 35s - loss: 0.1010 - val_loss: 0.0989\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 35s - loss: 0.1003 - val_loss: 0.0974\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 35s - loss: 0.0999 - val_loss: 0.0968\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 35s - loss: 0.0996 - val_loss: 0.0971\n",
      "476800/487006 [============================>.] - ETA: 0s-0.300659971047\n",
      "\n",
      "\n",
      "Starting CV for 7 128 10 relu adam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0995 - val_loss: 0.0956\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0963 - val_loss: 0.0947\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0962 - val_loss: 0.0951\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0962 - val_loss: 0.0953\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0961 - val_loss: 0.0948\n",
      "483712/487006 [============================>.] - ETA: 0s-0.296867664384\n",
      "\n",
      "\n",
      "Starting CV for 7 128 10 sigmoid rmsprop\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0987 - val_loss: 0.0946\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0956 - val_loss: 0.0944\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0953 - val_loss: 0.0937\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0950 - val_loss: 0.0935\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0948 - val_loss: 0.0935\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0947 - val_loss: 0.0941\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0946 - val_loss: 0.0935\n",
      "481664/487006 [============================>.] - ETA: 0s-0.295114641215\n",
      "\n",
      "\n",
      "Starting CV for 7 128 10 sigmoid sgd\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.1166 - val_loss: 0.1078\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.1071 - val_loss: 0.1046\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.1049 - val_loss: 0.1028\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.1032 - val_loss: 0.1011\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.1020 - val_loss: 0.0999\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.1010 - val_loss: 0.0989\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.1003 - val_loss: 0.0986\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0997 - val_loss: 0.0981\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0993 - val_loss: 0.0971\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 38s - loss: 0.0989 - val_loss: 0.0969\n",
      "481664/487006 [============================>.] - ETA: 0s-0.300263277841\n",
      "\n",
      "\n",
      "Starting CV for 7 128 10 sigmoid adam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0990 - val_loss: 0.0948\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0953 - val_loss: 0.0936\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0950 - val_loss: 0.0936\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0948 - val_loss: 0.0945\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0946 - val_loss: 0.0933\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0945 - val_loss: 0.0930\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0944 - val_loss: 0.0930\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 46s - loss: 0.0943 - val_loss: 0.0930\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 46s - loss: 0.0942 - val_loss: 0.0928\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 47s - loss: 0.0941 - val_loss: 0.0930\n",
      "482304/487006 [============================>.] - ETA: 0s-0.29398623225\n",
      "\n",
      "\n",
      "Starting CV for 18 128 10 relu rmsprop\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0975 - val_loss: 0.1004\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 57s - loss: 0.0956 - val_loss: 0.0951\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 56s - loss: 0.0951 - val_loss: 0.0938\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 56s - loss: 0.0948 - val_loss: 0.0937\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0945 - val_loss: 0.0929\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0943 - val_loss: 0.0926\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0941 - val_loss: 0.0930\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0940 - val_loss: 0.0934\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 57s - loss: 0.0939 - val_loss: 0.0931\n",
      "485760/487006 [============================>.] - ETA: 0s-0.293289914487\n",
      "\n",
      "\n",
      "Starting CV for 18 128 10 relu sgd\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.1080 - val_loss: 0.1037\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.1020 - val_loss: 0.1010\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.1005 - val_loss: 0.0988\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0996 - val_loss: 0.0974\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0989 - val_loss: 0.0964\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0986 - val_loss: 0.1007\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0982 - val_loss: 0.0952\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0979 - val_loss: 0.1133\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0976 - val_loss: 0.0950\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0974 - val_loss: 0.0952\n",
      "483072/487006 [============================>.] - ETA: 0s-0.298160864017\n",
      "\n",
      "\n",
      "Starting CV for 18 128 10 relu adam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0972 - val_loss: 0.0944\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0951 - val_loss: 0.0946\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0947 - val_loss: 0.0942\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0944 - val_loss: 0.0932\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 62s - loss: 0.0941 - val_loss: 0.0925\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 60s - loss: 0.0939 - val_loss: 0.0922\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 57s - loss: 0.0938 - val_loss: 0.0922\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 57s - loss: 0.0937 - val_loss: 0.0922\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0936 - val_loss: 0.0929\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 57s - loss: 0.0936 - val_loss: 0.0922\n",
      "486016/487006 [============================>.] - ETA: 0s-0.293161610784\n",
      "\n",
      "\n",
      "Starting CV for 18 128 10 sigmoid rmsprop\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0975 - val_loss: 0.0993\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 60s - loss: 0.0953 - val_loss: 0.0948\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0949 - val_loss: 0.0934\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0946 - val_loss: 0.0932\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0945 - val_loss: 0.0930\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0944 - val_loss: 0.0930\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0942 - val_loss: 0.0931\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 60s - loss: 0.0941 - val_loss: 0.0938\n",
      "483200/487006 [============================>.] - ETA: 0s-0.297987698507\n",
      "\n",
      "\n",
      "Starting CV for 18 128 10 sigmoid sgd\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.1141 - val_loss: 0.1072\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.1064 - val_loss: 0.1040\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 56s - loss: 0.1039 - val_loss: 0.1017\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.1024 - val_loss: 0.1003\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 55s - loss: 0.1011 - val_loss: 0.0989\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.1002 - val_loss: 0.0984\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 57s - loss: 0.0995 - val_loss: 0.0974\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 62s - loss: 0.0989 - val_loss: 0.1045\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0985 - val_loss: 0.0966\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 50s - loss: 0.0982 - val_loss: 0.0962\n",
      "484608/487006 [============================>.] - ETA: 0s-0.299696524668\n",
      "\n",
      "\n",
      "Starting CV for 18 128 10 sigmoid adam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/10\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0976 - val_loss: 0.0947\n",
      "Epoch 2/10\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0951 - val_loss: 0.0947\n",
      "Epoch 3/10\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.0947 - val_loss: 0.0933\n",
      "Epoch 4/10\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0944 - val_loss: 0.0932\n",
      "Epoch 5/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0942 - val_loss: 0.0926\n",
      "Epoch 6/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0940 - val_loss: 0.0925\n",
      "Epoch 7/10\n",
      "6397531/6397531 [==============================] - 50s - loss: 0.0939 - val_loss: 0.0924\n",
      "Epoch 8/10\n",
      "6397531/6397531 [==============================] - 50s - loss: 0.0937 - val_loss: 0.0922\n",
      "Epoch 9/10\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0936 - val_loss: 0.0925\n",
      "Epoch 10/10\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0935 - val_loss: 0.0921\n",
      "486656/487006 [============================>.] - ETA: 0s-0.293429831119\n"
     ]
    }
   ],
   "source": [
    "grid_scores = {}\n",
    "for no_hidden in param_grid[0]['no_hidden']:\n",
    "    for batch_size in param_grid[0]['batch_size']:\n",
    "        for nb_epoch in param_grid[0]['nb_epoch']:\n",
    "            for hidden_activation in param_grid[0]['hidden_activation']:\n",
    "                for optimizer in param_grid[0]['optimizer']:\n",
    "                    key = \" \".join([str(no_hidden), str(batch_size), str(nb_epoch), \n",
    "                                    str(hidden_activation), str(optimizer)])\n",
    "                    print(\"\\n\\nStarting CV for \" + key)\n",
    "                    clf = KerasClassifier(build_fn, no_hidden=no_hidden, batch_size=batch_size, \n",
    "                                          nb_epoch=nb_epoch, hidden_activation=hidden_activation, \n",
    "                                          optimizer=optimizer, \n",
    "                                          callbacks=[EarlyStopping(monitor='val_loss', patience=2)], \n",
    "                                          validation_split=0.2)\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    rmse = my_custom_scorer_neural(clf, X_val, y_val)\n",
    "                    grid_scores[key] = rmse\n",
    "                    print rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'18 128 10 relu adam': -0.29316161078437991,\n",
       " '18 128 10 relu rmsprop': -0.29328991448706099,\n",
       " '18 128 10 relu sgd': -0.29816086401735004,\n",
       " '18 128 10 sigmoid adam': -0.29342983111917242,\n",
       " '18 128 10 sigmoid rmsprop': -0.29798769850731432,\n",
       " '18 128 10 sigmoid sgd': -0.29969652466774416,\n",
       " '7 128 10 relu adam': -0.29686766438411266,\n",
       " '7 128 10 relu rmsprop': -0.29474118465005522,\n",
       " '7 128 10 relu sgd': -0.30065997104743691,\n",
       " '7 128 10 sigmoid adam': -0.29398623225040749,\n",
       " '7 128 10 sigmoid rmsprop': -0.29511464121481618,\n",
       " '7 128 10 sigmoid sgd': -0.30026327784054518}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/4(dict).pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_scores, 'Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/4(dict).pkl', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low memory grid search experimenting with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'batch_size': [128, 256], 'nb_epoch': [20], \n",
    "   'hidden_activation': ['relu', 'sigmoid'], \n",
    "   'optimizer': ['rmsprop', 'sgd', 'adam'], 'callbacks': [[EarlyStopping(monitor='val_loss', patience=2)]], \n",
    "   'validation_split': [0.2]}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_fn(no_hidden_1=18, no_hidden_2=8, hidden_activation='sigmoid', out_activation='sigmoid', \n",
    "             loss='mse', optimizer='rmsprop', random_state=0):\n",
    "    \n",
    "    np.random.seed(0)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(no_hidden_1, input_dim=28),\n",
    "        Activation(hidden_activation),\n",
    "        Dense(no_hidden_2), \n",
    "        Activation(hidden_activation),\n",
    "        Dense(1),\n",
    "        Activation(out_activation),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting CV for 128 20 relu rmsprop 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0974 - val_loss: 0.0941\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0952 - val_loss: 0.0952\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0947 - val_loss: 0.0932\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.0946 - val_loss: 0.0939\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.0945 - val_loss: 0.0932\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 56s - loss: 0.0944 - val_loss: 0.0927\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0942 - val_loss: 0.0932\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 60s - loss: 0.0941 - val_loss: 0.0925\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 10/20\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0940 - val_loss: 0.0923\n",
      "Epoch 11/20\n",
      "6397531/6397531 [==============================] - 63s - loss: 0.0940 - val_loss: 0.0938\n",
      "Epoch 12/20\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0939 - val_loss: 0.0931\n",
      "Epoch 13/20\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0940 - val_loss: 0.0931\n",
      "481536/487006 [============================>.] - ETA: 0s-0.294113010335\n",
      "\n",
      "\n",
      "Starting CV for 128 20 relu sgd 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.1059 - val_loss: 0.1003\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.1017 - val_loss: 0.1018\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.1002 - val_loss: 0.0982\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.0992 - val_loss: 0.0973\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.0986 - val_loss: 0.0961\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 60s - loss: 0.0981 - val_loss: 0.0962\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0977 - val_loss: 0.0961\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0975 - val_loss: 0.0963\n",
      "480384/487006 [============================>.] - ETA: 0s-0.299632170386\n",
      "\n",
      "\n",
      "Starting CV for 128 20 relu adam 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 67s - loss: 0.0968 - val_loss: 0.0939\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0950 - val_loss: 0.0933\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 64s - loss: 0.0944 - val_loss: 0.0927\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 67s - loss: 0.0940 - val_loss: 0.0937\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0937 - val_loss: 0.0927\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.0936 - val_loss: 0.0921\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0934 - val_loss: 0.0919\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 56s - loss: 0.0933 - val_loss: 0.0919\n",
      "Epoch 10/20\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0932 - val_loss: 0.0929\n",
      "Epoch 11/20\n",
      "6397531/6397531 [==============================] - 60s - loss: 0.0932 - val_loss: 0.0917\n",
      "Epoch 12/20\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0931 - val_loss: 0.0920\n",
      "Epoch 13/20\n",
      "6397531/6397531 [==============================] - 57s - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 14/20\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0930 - val_loss: 0.0919\n",
      "482048/487006 [============================>.] - ETA: 0s-0.292156485866\n",
      "\n",
      "\n",
      "Starting CV for 128 20 sigmoid rmsprop 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 60s - loss: 0.0976 - val_loss: 0.0942\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 62s - loss: 0.0953 - val_loss: 0.0948\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 65s - loss: 0.0949 - val_loss: 0.0933\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0946 - val_loss: 0.0935\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 65s - loss: 0.0944 - val_loss: 0.0935\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 56s - loss: 0.0943 - val_loss: 0.0927\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 62s - loss: 0.0941 - val_loss: 0.0937\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0940 - val_loss: 0.0923\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 58s - loss: 0.0939 - val_loss: 0.0929\n",
      "Epoch 10/20\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 11/20\n",
      "6397531/6397531 [==============================] - 60s - loss: 0.0938 - val_loss: 0.0934\n",
      "485376/487006 [============================>.] - ETA: 0s-0.293941992371\n",
      "\n",
      "\n",
      "Starting CV for 128 20 sigmoid sgd 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.1205 - val_loss: 0.1167\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.1139 - val_loss: 0.1077\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 57s - loss: 0.1070 - val_loss: 0.1047\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.1048 - val_loss: 0.1030\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.1026 - val_loss: 0.1013\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.1011 - val_loss: 0.0991\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 55s - loss: 0.1000 - val_loss: 0.0986\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0992 - val_loss: 0.0974\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0986 - val_loss: 0.0968\n",
      "Epoch 10/20\n",
      "6397531/6397531 [==============================] - 59s - loss: 0.0983 - val_loss: 0.0964\n",
      "Epoch 11/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.0979 - val_loss: 0.0965\n",
      "Epoch 12/20\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.0976 - val_loss: 0.0964\n",
      "Epoch 13/20\n",
      "6397531/6397531 [==============================] - 57s - loss: 0.0974 - val_loss: 0.0974\n",
      "Epoch 14/20\n",
      "6397531/6397531 [==============================] - 55s - loss: 0.0973 - val_loss: 0.0958\n",
      "Epoch 15/20\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.0971 - val_loss: 0.0951\n",
      "Epoch 16/20\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0969 - val_loss: 0.0952\n",
      "Epoch 17/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.0968 - val_loss: 0.0951\n",
      "Epoch 18/20\n",
      "6397531/6397531 [==============================] - 57s - loss: 0.0967 - val_loss: 0.0948\n",
      "Epoch 19/20\n",
      "6397531/6397531 [==============================] - 56s - loss: 0.0966 - val_loss: 0.0947\n",
      "Epoch 20/20\n",
      "6397531/6397531 [==============================] - 55s - loss: 0.0966 - val_loss: 0.0949\n",
      "484992/487006 [============================>.] - ETA: 0s-0.298151601655\n",
      "\n",
      "\n",
      "Starting CV for 128 20 sigmoid adam 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 62s - loss: 0.0975 - val_loss: 0.0945\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 63s - loss: 0.0950 - val_loss: 0.0936\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 70s - loss: 0.0947 - val_loss: 0.0935\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 65s - loss: 0.0944 - val_loss: 0.0941\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 61s - loss: 0.0941 - val_loss: 0.0934\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 65s - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 66s - loss: 0.0937 - val_loss: 0.0928\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 67s - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 66s - loss: 0.0934 - val_loss: 0.0920\n",
      "Epoch 10/20\n",
      "6397531/6397531 [==============================] - 67s - loss: 0.0933 - val_loss: 0.0922\n",
      "Epoch 11/20\n",
      "6397531/6397531 [==============================] - 64s - loss: 0.0932 - val_loss: 0.0917\n",
      "Epoch 12/20\n",
      "6397531/6397531 [==============================] - 67s - loss: 0.0931 - val_loss: 0.0921\n",
      "Epoch 13/20\n",
      "6397531/6397531 [==============================] - 65s - loss: 0.0931 - val_loss: 0.0916\n",
      "Epoch 14/20\n",
      "6397531/6397531 [==============================] - 65s - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 15/20\n",
      "6397531/6397531 [==============================] - 65s - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 16/20\n",
      "6397531/6397531 [==============================] - 66s - loss: 0.0929 - val_loss: 0.0916\n",
      "Epoch 17/20\n",
      "6397531/6397531 [==============================] - 65s - loss: 0.0929 - val_loss: 0.0915\n",
      "Epoch 18/20\n",
      "6397531/6397531 [==============================] - 62s - loss: 0.0929 - val_loss: 0.0915\n",
      "Epoch 19/20\n",
      "6397531/6397531 [==============================] - 64s - loss: 0.0928 - val_loss: 0.0915\n",
      "Epoch 20/20\n",
      "6397531/6397531 [==============================] - 63s - loss: 0.0928 - val_loss: 0.0916\n",
      "485504/487006 [============================>.] - ETA: 0s-0.291829121383\n",
      "\n",
      "\n",
      "Starting CV for 256 20 relu rmsprop 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0977 - val_loss: 0.0957\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0954 - val_loss: 0.0961\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0949 - val_loss: 0.0934\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0945 - val_loss: 0.0931\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0943 - val_loss: 0.0931\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0942 - val_loss: 0.0926\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0940 - val_loss: 0.0930\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0939 - val_loss: 0.0929\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0938 - val_loss: 0.0929\n",
      "480256/487006 [============================>.] - ETA: 0s-0.293167101123\n",
      "\n",
      "\n",
      "Starting CV for 256 20 relu sgd 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.1077 - val_loss: 0.1025\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.1035 - val_loss: 0.1073\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.1019 - val_loss: 0.0998\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.1009 - val_loss: 0.0976\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.1001 - val_loss: 0.0983\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 37s - loss: 0.0995 - val_loss: 0.1022\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0990 - val_loss: 0.0958\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0985 - val_loss: 0.0967\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 35s - loss: 0.0983 - val_loss: 0.0953\n",
      "Epoch 10/20\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0981 - val_loss: 0.0988\n",
      "Epoch 11/20\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0980 - val_loss: 0.0963\n",
      "Epoch 12/20\n",
      "6397531/6397531 [==============================] - 34s - loss: 0.0976 - val_loss: 0.0957\n",
      "480768/487006 [============================>.] - ETA: 0s-0.29864323117\n",
      "\n",
      "\n",
      "Starting CV for 256 20 relu adam 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0970 - val_loss: 0.0957\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0951 - val_loss: 0.0938\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0947 - val_loss: 0.0941\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0943 - val_loss: 0.0948\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0941 - val_loss: 0.0933\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0939 - val_loss: 0.0924\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0937 - val_loss: 0.0927\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0934 - val_loss: 0.0923\n",
      "Epoch 10/20\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0933 - val_loss: 0.0936\n",
      "Epoch 11/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 12/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 13/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0931 - val_loss: 0.0920\n",
      "Epoch 14/20\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 15/20\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0931 - val_loss: 0.0938\n",
      "Epoch 16/20\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 17/20\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0930 - val_loss: 0.0916\n",
      "Epoch 18/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0930 - val_loss: 0.0917\n",
      "Epoch 19/20\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0930 - val_loss: 0.0914\n",
      "Epoch 20/20\n",
      "6397531/6397531 [==============================] - 42s - loss: 0.0929 - val_loss: 0.0918\n",
      "484864/487006 [============================>.] - ETA: 0s-0.292208241514\n",
      "\n",
      "\n",
      "Starting CV for 256 20 sigmoid rmsprop 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0985 - val_loss: 0.0948\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0954 - val_loss: 0.0953\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0950 - val_loss: 0.0940\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0947 - val_loss: 0.0934\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0945 - val_loss: 0.0937\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0943 - val_loss: 0.0932\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0942 - val_loss: 0.0931\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0941 - val_loss: 0.0929\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0940 - val_loss: 0.0927\n",
      "Epoch 10/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0938 - val_loss: 0.0926\n",
      "Epoch 11/20\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0937 - val_loss: 0.0933\n",
      "Epoch 12/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0936 - val_loss: 0.0925\n",
      "Epoch 13/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0936 - val_loss: 0.0922\n",
      "Epoch 14/20\n",
      "6397531/6397531 [==============================] - 46s - loss: 0.0935 - val_loss: 0.0935\n",
      "Epoch 15/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0934 - val_loss: 0.0926\n",
      "Epoch 16/20\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 17/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0933 - val_loss: 0.0918\n",
      "Epoch 18/20\n",
      "6397531/6397531 [==============================] - 46s - loss: 0.0933 - val_loss: 0.0918\n",
      "Epoch 19/20\n",
      "6397531/6397531 [==============================] - 44s - loss: 0.0933 - val_loss: 0.0919\n",
      "Epoch 20/20\n",
      "6397531/6397531 [==============================] - 45s - loss: 0.0932 - val_loss: 0.0919\n",
      "483840/487006 [============================>.] - ETA: 0s-0.293164204631\n",
      "\n",
      "\n",
      "Starting CV for 256 20 sigmoid sgd 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.1215 - val_loss: 0.1185\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.1194 - val_loss: 0.1167\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.1165 - val_loss: 0.1125\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.1113 - val_loss: 0.1078\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.1077 - val_loss: 0.1060\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.1063 - val_loss: 0.1047\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.1052 - val_loss: 0.1038\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.1042 - val_loss: 0.1025\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.1030 - val_loss: 0.1014\n",
      "Epoch 10/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.1019 - val_loss: 0.1002\n",
      "Epoch 11/20\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.1012 - val_loss: 0.0997\n",
      "Epoch 12/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.1005 - val_loss: 0.0991\n",
      "Epoch 13/20\n",
      "6397531/6397531 [==============================] - 40s - loss: 0.0999 - val_loss: 0.0990\n",
      "Epoch 14/20\n",
      "6397531/6397531 [==============================] - 43s - loss: 0.0994 - val_loss: 0.0979\n",
      "Epoch 15/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0990 - val_loss: 0.0973\n",
      "Epoch 16/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0986 - val_loss: 0.0968\n",
      "Epoch 17/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0984 - val_loss: 0.0965\n",
      "Epoch 18/20\n",
      "6397531/6397531 [==============================] - 39s - loss: 0.0981 - val_loss: 0.0962\n",
      "Epoch 19/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0979 - val_loss: 0.0960\n",
      "Epoch 20/20\n",
      "6397531/6397531 [==============================] - 41s - loss: 0.0977 - val_loss: 0.0962\n",
      "485632/487006 [============================>.] - ETA: 0s-0.300756732685\n",
      "\n",
      "\n",
      "Starting CV for 256 20 sigmoid adam 1\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0987 - val_loss: 0.0947\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0950 - val_loss: 0.0934\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0947 - val_loss: 0.0944\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0945 - val_loss: 0.0941\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.0944 - val_loss: 0.0934\n",
      "486144/487006 [============================>.] - ETA: 0s-0.2948639549\n"
     ]
    }
   ],
   "source": [
    "grid_scores = {}\n",
    "ctr = 0\n",
    "for batch_size in param_grid[0]['batch_size']:\n",
    "    for nb_epoch in param_grid[0]['nb_epoch']:\n",
    "        for hidden_activation in param_grid[0]['hidden_activation']:\n",
    "            for optimizer in param_grid[0]['optimizer']:\n",
    "                ctr += 1\n",
    "                key = \" \".join([str(batch_size), str(nb_epoch), str(hidden_activation), str(optimizer)])\n",
    "                print(\"\\n\\nStarting CV for \" + key), 1\n",
    "                clf = KerasClassifier(build_fn, batch_size=batch_size, \n",
    "                                      nb_epoch=nb_epoch, hidden_activation=hidden_activation, \n",
    "                                      optimizer=optimizer, \n",
    "                                      callbacks=[EarlyStopping(monitor='val_loss', patience=2)], \n",
    "                                      validation_split=0.2)\n",
    "                clf.fit(X_train, y_train)\n",
    "                rmse = my_custom_scorer_neural(clf, X_val, y_val)\n",
    "                grid_scores[key] = rmse\n",
    "                print rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'128 20 relu adam': -0.29215648586630444,\n",
       " '128 20 relu rmsprop': -0.2941130103354781,\n",
       " '128 20 relu sgd': -0.29963217038595874,\n",
       " '128 20 sigmoid adam': -0.29182912138253392,\n",
       " '128 20 sigmoid rmsprop': -0.29394199237117868,\n",
       " '128 20 sigmoid sgd': -0.29815160165516991,\n",
       " '256 20 relu adam': -0.29220824151446928,\n",
       " '256 20 relu rmsprop': -0.29316710112333955,\n",
       " '256 20 relu sgd': -0.29864323117034253,\n",
       " '256 20 sigmoid adam': -0.29486395490022232,\n",
       " '256 20 sigmoid rmsprop': -0.29316420463096438,\n",
       " '256 20 sigmoid sgd': -0.30075673268512754}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/5(dict).pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_scores, 'Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/5(dict).pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.0987 - val_loss: 0.0947\n",
      "Epoch 2/20\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.0950 - val_loss: 0.0934\n",
      "Epoch 3/20\n",
      "6397531/6397531 [==============================] - 52s - loss: 0.0947 - val_loss: 0.0944\n",
      "Epoch 4/20\n",
      "6397531/6397531 [==============================] - 50s - loss: 0.0945 - val_loss: 0.0941\n",
      "Epoch 5/20\n",
      "6397531/6397531 [==============================] - 47s - loss: 0.0944 - val_loss: 0.0934\n",
      "Epoch 6/20\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0942 - val_loss: 0.0926\n",
      "Epoch 7/20\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0941 - val_loss: 0.0932\n",
      "Epoch 8/20\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0939 - val_loss: 0.0924\n",
      "Epoch 9/20\n",
      "6397531/6397531 [==============================] - 53s - loss: 0.0938 - val_loss: 0.0923\n",
      "Epoch 10/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.0937 - val_loss: 0.0930\n",
      "Epoch 11/20\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0936 - val_loss: 0.0920\n",
      "Epoch 12/20\n",
      "6397531/6397531 [==============================] - 55s - loss: 0.0934 - val_loss: 0.0925\n",
      "Epoch 13/20\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 14/20\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 15/20\n",
      "6397531/6397531 [==============================] - 48s - loss: 0.0932 - val_loss: 0.0918\n",
      "Epoch 16/20\n",
      "6397531/6397531 [==============================] - 54s - loss: 0.0932 - val_loss: 0.0918\n",
      "Epoch 17/20\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0931 - val_loss: 0.0917\n",
      "Epoch 18/20\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0931 - val_loss: 0.0917\n",
      "Epoch 19/20\n",
      "6397531/6397531 [==============================] - 51s - loss: 0.0930 - val_loss: 0.0916\n",
      "Epoch 20/20\n",
      "6397531/6397531 [==============================] - 49s - loss: 0.0930 - val_loss: 0.0922\n",
      "483840/487006 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.29258125686035824"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KerasClassifier(build_fn, batch_size=256, \n",
    "                      nb_epoch=20, hidden_activation='sigmoid', \n",
    "                      optimizer='adam', \n",
    "                      validation_split=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "rmse = my_custom_scorer_neural(clf, X_val, y_val)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### \"Grid search\" for my low memory laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'batch_size': [128, 256], 'nb_epoch': [20], \n",
    "   'hidden_activation': ['relu', 'sigmoid'], \n",
    "   'optimizer': ['adagrad', 'adadelta', 'adamax', 'nadam'], 'callbacks': [[EarlyStopping(monitor='val_loss', patience=2)]], \n",
    "   'validation_split': [0.2]}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_fn(no_hidden=14, hidden_activation='sigmoid', out_activation='sigmoid', \n",
    "             loss='mse', optimizer='rmsprop', random_state=0):\n",
    "    \n",
    "    np.random.seed(0)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(no_hidden, input_dim=28),\n",
    "        Activation(hidden_activation),\n",
    "        Dense(1),\n",
    "        Activation(out_activation),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting CV for 128 20 relu adagrad\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "30s - loss: 0.1008 - val_loss: 0.0970\n",
      "Epoch 2/20\n",
      "30s - loss: 0.0978 - val_loss: 0.0960\n",
      "Epoch 3/20\n",
      "29s - loss: 0.0970 - val_loss: 0.0953\n",
      "Epoch 4/20\n",
      "28s - loss: 0.0963 - val_loss: 0.0948\n",
      "Epoch 5/20\n",
      "28s - loss: 0.0960 - val_loss: 0.0947\n",
      "Epoch 6/20\n",
      "29s - loss: 0.0957 - val_loss: 0.0944\n",
      "Epoch 7/20\n",
      "28s - loss: 0.0956 - val_loss: 0.0943\n",
      "Epoch 8/20\n",
      "28s - loss: 0.0955 - val_loss: 0.0943\n",
      "Epoch 9/20\n",
      "28s - loss: 0.0954 - val_loss: 0.0942\n",
      "Epoch 10/20\n",
      "28s - loss: 0.0953 - val_loss: 0.0941\n",
      "Epoch 11/20\n",
      "28s - loss: 0.0952 - val_loss: 0.0940\n",
      "Epoch 12/20\n",
      "28s - loss: 0.0952 - val_loss: 0.0940\n",
      "Epoch 13/20\n",
      "29s - loss: 0.0951 - val_loss: 0.0939\n",
      "Epoch 14/20\n",
      "28s - loss: 0.0951 - val_loss: 0.0940\n",
      "Epoch 15/20\n",
      "28s - loss: 0.0950 - val_loss: 0.0938\n",
      "Epoch 16/20\n",
      "28s - loss: 0.0950 - val_loss: 0.0938\n",
      "Epoch 17/20\n",
      "28s - loss: 0.0950 - val_loss: 0.0938\n",
      "Epoch 18/20\n",
      "28s - loss: 0.0949 - val_loss: 0.0938\n",
      "Epoch 19/20\n",
      "28s - loss: 0.0949 - val_loss: 0.0937\n",
      "Epoch 20/20\n",
      "28s - loss: 0.0949 - val_loss: 0.0937\n",
      "-0.29532124753\n",
      "\n",
      "\n",
      "Starting CV for 128 20 relu adadelta\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "26s - loss: 0.0992 - val_loss: 0.0948\n",
      "Epoch 2/20\n",
      "26s - loss: 0.0956 - val_loss: 0.0937\n",
      "Epoch 3/20\n",
      "31s - loss: 0.0951 - val_loss: 0.0936\n",
      "Epoch 4/20\n",
      "27s - loss: 0.0949 - val_loss: 0.0935\n",
      "Epoch 5/20\n",
      "29s - loss: 0.0948 - val_loss: 0.0936\n",
      "Epoch 6/20\n",
      "30s - loss: 0.0948 - val_loss: 0.0933\n",
      "Epoch 7/20\n",
      "29s - loss: 0.0947 - val_loss: 0.0932\n",
      "Epoch 8/20\n",
      "30s - loss: 0.0946 - val_loss: 0.0938\n",
      "Epoch 9/20\n",
      "28s - loss: 0.0945 - val_loss: 0.0931\n",
      "Epoch 10/20\n",
      "28s - loss: 0.0945 - val_loss: 0.0930\n",
      "Epoch 11/20\n",
      "29s - loss: 0.0944 - val_loss: 0.0938\n",
      "Epoch 12/20\n",
      "28s - loss: 0.0944 - val_loss: 0.0933\n",
      "Epoch 13/20\n",
      "29s - loss: 0.0943 - val_loss: 0.0929\n",
      "Epoch 14/20\n",
      "28s - loss: 0.0943 - val_loss: 0.0933\n",
      "Epoch 15/20\n",
      "29s - loss: 0.0943 - val_loss: 0.0928\n",
      "Epoch 16/20\n",
      "28s - loss: 0.0943 - val_loss: 0.0929\n",
      "Epoch 17/20\n",
      "28s - loss: 0.0942 - val_loss: 0.0932\n",
      "Epoch 18/20\n",
      "29s - loss: 0.0942 - val_loss: 0.0929\n",
      "-0.293855686049\n",
      "\n",
      "\n",
      "Starting CV for 128 20 relu adamax\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "34s - loss: 0.0983 - val_loss: 0.0947\n",
      "Epoch 2/20\n",
      "31s - loss: 0.0953 - val_loss: 0.0935\n",
      "Epoch 3/20\n",
      "31s - loss: 0.0949 - val_loss: 0.0933\n",
      "Epoch 4/20\n",
      "32s - loss: 0.0947 - val_loss: 0.0934\n",
      "Epoch 5/20\n",
      "31s - loss: 0.0946 - val_loss: 0.0931\n",
      "Epoch 6/20\n",
      "31s - loss: 0.0945 - val_loss: 0.0931\n",
      "Epoch 7/20\n",
      "31s - loss: 0.0945 - val_loss: 0.0929\n",
      "Epoch 8/20\n",
      "31s - loss: 0.0944 - val_loss: 0.0934\n",
      "Epoch 9/20\n",
      "31s - loss: 0.0943 - val_loss: 0.0933\n",
      "Epoch 10/20\n",
      "31s - loss: 0.0943 - val_loss: 0.0929\n",
      "Epoch 11/20\n",
      "36s - loss: 0.0942 - val_loss: 0.0930\n",
      "Epoch 12/20\n",
      "32s - loss: 0.0942 - val_loss: 0.0928\n",
      "Epoch 13/20\n",
      "31s - loss: 0.0941 - val_loss: 0.0927\n",
      "Epoch 14/20\n",
      "31s - loss: 0.0941 - val_loss: 0.0927\n",
      "Epoch 15/20\n",
      "32s - loss: 0.0940 - val_loss: 0.0932\n",
      "Epoch 16/20\n",
      "32s - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 17/20\n",
      "32s - loss: 0.0939 - val_loss: 0.0927\n",
      "Epoch 18/20\n",
      "32s - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 19/20\n",
      "32s - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 20/20\n",
      "32s - loss: 0.0939 - val_loss: 0.0928\n",
      "-0.294552408798\n",
      "\n",
      "\n",
      "Starting CV for 128 20 relu nadam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "35s - loss: 0.0972 - val_loss: 0.0946\n",
      "Epoch 2/20\n",
      "35s - loss: 0.0951 - val_loss: 0.0934\n",
      "Epoch 3/20\n",
      "35s - loss: 0.0948 - val_loss: 0.0931\n",
      "Epoch 4/20\n",
      "35s - loss: 0.0945 - val_loss: 0.0929\n",
      "Epoch 5/20\n",
      "38s - loss: 0.0942 - val_loss: 0.0927\n",
      "Epoch 6/20\n",
      "41s - loss: 0.0940 - val_loss: 0.0924\n",
      "Epoch 7/20\n",
      "42s - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 8/20\n",
      "36s - loss: 0.0938 - val_loss: 0.0927\n",
      "Epoch 9/20\n",
      "36s - loss: 0.0937 - val_loss: 0.0926\n",
      "-0.294134203463\n",
      "\n",
      "\n",
      "Starting CV for 128 20 sigmoid adagrad\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "30s - loss: 0.1036 - val_loss: 0.0995\n",
      "Epoch 2/20\n",
      "31s - loss: 0.0997 - val_loss: 0.0975\n",
      "Epoch 3/20\n",
      "30s - loss: 0.0985 - val_loss: 0.0967\n",
      "Epoch 4/20\n",
      "30s - loss: 0.0978 - val_loss: 0.0962\n",
      "Epoch 5/20\n",
      "30s - loss: 0.0974 - val_loss: 0.0959\n",
      "Epoch 6/20\n",
      "30s - loss: 0.0971 - val_loss: 0.0956\n",
      "Epoch 7/20\n",
      "30s - loss: 0.0968 - val_loss: 0.0954\n",
      "Epoch 8/20\n",
      "30s - loss: 0.0966 - val_loss: 0.0952\n",
      "Epoch 9/20\n",
      "35s - loss: 0.0964 - val_loss: 0.0952\n",
      "Epoch 10/20\n",
      "30s - loss: 0.0963 - val_loss: 0.0950\n",
      "Epoch 11/20\n",
      "31s - loss: 0.0962 - val_loss: 0.0949\n",
      "Epoch 12/20\n",
      "31s - loss: 0.0961 - val_loss: 0.0949\n",
      "Epoch 13/20\n",
      "31s - loss: 0.0960 - val_loss: 0.0948\n",
      "Epoch 14/20\n",
      "31s - loss: 0.0959 - val_loss: 0.0947\n",
      "Epoch 15/20\n",
      "31s - loss: 0.0959 - val_loss: 0.0946\n",
      "Epoch 16/20\n",
      "31s - loss: 0.0958 - val_loss: 0.0946\n",
      "Epoch 17/20\n",
      "31s - loss: 0.0958 - val_loss: 0.0946\n",
      "Epoch 18/20\n",
      "31s - loss: 0.0957 - val_loss: 0.0945\n",
      "Epoch 19/20\n",
      "31s - loss: 0.0957 - val_loss: 0.0945\n",
      "Epoch 20/20\n",
      "30s - loss: 0.0956 - val_loss: 0.0945\n",
      "-0.296519714059\n",
      "\n",
      "\n",
      "Starting CV for 128 20 sigmoid adadelta\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "28s - loss: 0.0999 - val_loss: 0.0950\n",
      "Epoch 2/20\n",
      "29s - loss: 0.0956 - val_loss: 0.0941\n",
      "Epoch 3/20\n",
      "35s - loss: 0.0952 - val_loss: 0.0938\n",
      "Epoch 4/20\n",
      "28s - loss: 0.0950 - val_loss: 0.0937\n",
      "Epoch 5/20\n",
      "28s - loss: 0.0948 - val_loss: 0.0937\n",
      "Epoch 6/20\n",
      "28s - loss: 0.0947 - val_loss: 0.0933\n",
      "Epoch 7/20\n",
      "28s - loss: 0.0946 - val_loss: 0.0932\n",
      "Epoch 8/20\n",
      "28s - loss: 0.0945 - val_loss: 0.0936\n",
      "Epoch 9/20\n",
      "28s - loss: 0.0944 - val_loss: 0.0930\n",
      "Epoch 10/20\n",
      "28s - loss: 0.0943 - val_loss: 0.0930\n",
      "Epoch 11/20\n",
      "28s - loss: 0.0942 - val_loss: 0.0934\n",
      "Epoch 12/20\n",
      "29s - loss: 0.0942 - val_loss: 0.0930\n",
      "Epoch 13/20\n",
      "29s - loss: 0.0941 - val_loss: 0.0927\n",
      "Epoch 14/20\n",
      "29s - loss: 0.0941 - val_loss: 0.0930\n",
      "Epoch 15/20\n",
      "29s - loss: 0.0941 - val_loss: 0.0928\n",
      "Epoch 16/20\n",
      "29s - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 17/20\n",
      "29s - loss: 0.0940 - val_loss: 0.0929\n",
      "Epoch 18/20\n",
      "29s - loss: 0.0939 - val_loss: 0.0927\n",
      "Epoch 19/20\n",
      "29s - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 20/20\n",
      "29s - loss: 0.0938 - val_loss: 0.0925\n",
      "-0.293433012272\n",
      "\n",
      "\n",
      "Starting CV for 128 20 sigmoid adamax\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "33s - loss: 0.0982 - val_loss: 0.0947\n",
      "Epoch 2/20\n",
      "32s - loss: 0.0953 - val_loss: 0.0937\n",
      "Epoch 3/20\n",
      "32s - loss: 0.0949 - val_loss: 0.0935\n",
      "Epoch 4/20\n",
      "36s - loss: 0.0946 - val_loss: 0.0934\n",
      "Epoch 5/20\n",
      "32s - loss: 0.0944 - val_loss: 0.0930\n",
      "Epoch 6/20\n",
      "32s - loss: 0.0943 - val_loss: 0.0929\n",
      "Epoch 7/20\n",
      "32s - loss: 0.0942 - val_loss: 0.0928\n",
      "Epoch 8/20\n",
      "32s - loss: 0.0941 - val_loss: 0.0928\n",
      "Epoch 9/20\n",
      "32s - loss: 0.0940 - val_loss: 0.0927\n",
      "Epoch 10/20\n",
      "32s - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 11/20\n",
      "31s - loss: 0.0938 - val_loss: 0.0929\n",
      "Epoch 12/20\n",
      "31s - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 13/20\n",
      "31s - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 14/20\n",
      "36s - loss: 0.0936 - val_loss: 0.0924\n",
      "Epoch 15/20\n",
      "32s - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 16/20\n",
      "32s - loss: 0.0935 - val_loss: 0.0921\n",
      "Epoch 17/20\n",
      "32s - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 18/20\n",
      "32s - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 19/20\n",
      "32s - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 20/20\n",
      "32s - loss: 0.0934 - val_loss: 0.0920\n",
      "-0.292619408649\n",
      "\n",
      "\n",
      "Starting CV for 128 20 sigmoid nadam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "34s - loss: 0.0969 - val_loss: 0.0941\n",
      "Epoch 2/20\n",
      "34s - loss: 0.0948 - val_loss: 0.0931\n",
      "Epoch 3/20\n",
      "34s - loss: 0.0943 - val_loss: 0.0930\n",
      "Epoch 4/20\n",
      "33s - loss: 0.0940 - val_loss: 0.0923\n",
      "Epoch 5/20\n",
      "34s - loss: 0.0938 - val_loss: 0.0922\n",
      "Epoch 6/20\n",
      "34s - loss: 0.0937 - val_loss: 0.0920\n",
      "Epoch 7/20\n",
      "34s - loss: 0.0936 - val_loss: 0.0921\n",
      "Epoch 8/20\n",
      "34s - loss: 0.0935 - val_loss: 0.0924\n",
      "Epoch 9/20\n",
      "34s - loss: 0.0934 - val_loss: 0.0921\n",
      "-0.293257563664\n",
      "\n",
      "\n",
      "Starting CV for 256 20 relu adagrad\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "22s - loss: 0.1015 - val_loss: 0.0973\n",
      "Epoch 2/20\n",
      "22s - loss: 0.0980 - val_loss: 0.0962\n",
      "Epoch 3/20\n",
      "21s - loss: 0.0971 - val_loss: 0.0954\n",
      "Epoch 4/20\n",
      "22s - loss: 0.0964 - val_loss: 0.0949\n",
      "Epoch 5/20\n",
      "22s - loss: 0.0960 - val_loss: 0.0947\n",
      "Epoch 6/20\n",
      "22s - loss: 0.0958 - val_loss: 0.0945\n",
      "Epoch 7/20\n",
      "22s - loss: 0.0956 - val_loss: 0.0944\n",
      "Epoch 8/20\n",
      "22s - loss: 0.0955 - val_loss: 0.0943\n",
      "Epoch 9/20\n",
      "22s - loss: 0.0954 - val_loss: 0.0942\n",
      "Epoch 10/20\n",
      "21s - loss: 0.0953 - val_loss: 0.0941\n",
      "Epoch 11/20\n",
      "22s - loss: 0.0952 - val_loss: 0.0941\n",
      "Epoch 12/20\n",
      "22s - loss: 0.0952 - val_loss: 0.0940\n",
      "Epoch 13/20\n",
      "22s - loss: 0.0951 - val_loss: 0.0939\n",
      "Epoch 14/20\n",
      "21s - loss: 0.0951 - val_loss: 0.0940\n",
      "Epoch 15/20\n",
      "22s - loss: 0.0950 - val_loss: 0.0939\n",
      "Epoch 16/20\n",
      "22s - loss: 0.0950 - val_loss: 0.0938\n",
      "Epoch 17/20\n",
      "22s - loss: 0.0950 - val_loss: 0.0938\n",
      "Epoch 18/20\n",
      "22s - loss: 0.0949 - val_loss: 0.0938\n",
      "Epoch 19/20\n",
      "22s - loss: 0.0949 - val_loss: 0.0938\n",
      "Epoch 20/20\n",
      "22s - loss: 0.0949 - val_loss: 0.0937\n",
      "-0.295341160437\n",
      "\n",
      "\n",
      "Starting CV for 256 20 relu adadelta\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "22s - loss: 0.1009 - val_loss: 0.0954\n",
      "Epoch 2/20\n",
      "19s - loss: 0.0960 - val_loss: 0.0943\n",
      "Epoch 3/20\n",
      "19s - loss: 0.0953 - val_loss: 0.0941\n",
      "Epoch 4/20\n",
      "18s - loss: 0.0951 - val_loss: 0.0939\n",
      "Epoch 5/20\n",
      "20s - loss: 0.0950 - val_loss: 0.0939\n",
      "Epoch 6/20\n",
      "20s - loss: 0.0949 - val_loss: 0.0938\n",
      "Epoch 7/20\n",
      "18s - loss: 0.0949 - val_loss: 0.0936\n",
      "Epoch 8/20\n",
      "18s - loss: 0.0948 - val_loss: 0.0949\n",
      "Epoch 9/20\n",
      "18s - loss: 0.0948 - val_loss: 0.0935\n",
      "Epoch 10/20\n",
      "18s - loss: 0.0948 - val_loss: 0.0935\n",
      "Epoch 11/20\n",
      "18s - loss: 0.0947 - val_loss: 0.0946\n",
      "Epoch 12/20\n",
      "19s - loss: 0.0947 - val_loss: 0.0937\n",
      "Epoch 13/20\n",
      "18s - loss: 0.0947 - val_loss: 0.0935\n",
      "Epoch 14/20\n",
      "18s - loss: 0.0947 - val_loss: 0.0936\n",
      "Epoch 15/20\n",
      "18s - loss: 0.0946 - val_loss: 0.0934\n",
      "Epoch 16/20\n",
      "18s - loss: 0.0946 - val_loss: 0.0934\n",
      "Epoch 17/20\n",
      "18s - loss: 0.0945 - val_loss: 0.0940\n",
      "Epoch 18/20\n",
      "19s - loss: 0.0945 - val_loss: 0.0931\n",
      "Epoch 19/20\n",
      "19s - loss: 0.0944 - val_loss: 0.0932\n",
      "Epoch 20/20\n",
      "18s - loss: 0.0943 - val_loss: 0.0930\n",
      "-0.294142783377\n",
      "\n",
      "\n",
      "Starting CV for 256 20 relu adamax\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "22s - loss: 0.1002 - val_loss: 0.0947\n",
      "Epoch 2/20\n",
      "27s - loss: 0.0954 - val_loss: 0.0937\n",
      "Epoch 3/20\n",
      "23s - loss: 0.0949 - val_loss: 0.0933\n",
      "Epoch 4/20\n",
      "23s - loss: 0.0946 - val_loss: 0.0931\n",
      "Epoch 5/20\n",
      "22s - loss: 0.0944 - val_loss: 0.0929\n",
      "Epoch 6/20\n",
      "23s - loss: 0.0943 - val_loss: 0.0928\n",
      "Epoch 7/20\n",
      "23s - loss: 0.0943 - val_loss: 0.0933\n",
      "Epoch 8/20\n",
      "22s - loss: 0.0942 - val_loss: 0.0928\n",
      "Epoch 9/20\n",
      "23s - loss: 0.0942 - val_loss: 0.0928\n",
      "Epoch 10/20\n",
      "23s - loss: 0.0941 - val_loss: 0.0931\n",
      "Epoch 11/20\n",
      "22s - loss: 0.0941 - val_loss: 0.0937\n",
      "-0.295726264111\n",
      "\n",
      "\n",
      "Starting CV for 256 20 relu nadam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "23s - loss: 0.0978 - val_loss: 0.0945\n",
      "Epoch 2/20\n",
      "23s - loss: 0.0949 - val_loss: 0.0936\n",
      "Epoch 3/20\n",
      "23s - loss: 0.0946 - val_loss: 0.0932\n",
      "Epoch 4/20\n",
      "23s - loss: 0.0945 - val_loss: 0.0933\n",
      "Epoch 5/20\n",
      "23s - loss: 0.0944 - val_loss: 0.0929\n",
      "Epoch 6/20\n",
      "23s - loss: 0.0944 - val_loss: 0.0927\n",
      "Epoch 7/20\n",
      "23s - loss: 0.0943 - val_loss: 0.0931\n",
      "Epoch 8/20\n",
      "24s - loss: 0.0942 - val_loss: 0.0929\n",
      "Epoch 9/20\n",
      "24s - loss: 0.0940 - val_loss: 0.0925\n",
      "Epoch 10/20\n",
      "24s - loss: 0.0939 - val_loss: 0.0924\n",
      "Epoch 11/20\n",
      "23s - loss: 0.0938 - val_loss: 0.0930\n",
      "Epoch 12/20\n",
      "23s - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 13/20\n",
      "24s - loss: 0.0937 - val_loss: 0.0923\n",
      "Epoch 14/20\n",
      "23s - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 15/20\n",
      "23s - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 16/20\n",
      "23s - loss: 0.0936 - val_loss: 0.0921\n",
      "Epoch 17/20\n",
      "24s - loss: 0.0936 - val_loss: 0.0924\n",
      "Epoch 18/20\n",
      "24s - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 19/20\n",
      "24s - loss: 0.0935 - val_loss: 0.0921\n",
      "Epoch 20/20\n",
      "24s - loss: 0.0935 - val_loss: 0.0921\n",
      "-0.292772471379\n",
      "\n",
      "\n",
      "Starting CV for 256 20 sigmoid adagrad\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "24s - loss: 0.1050 - val_loss: 0.1008\n",
      "Epoch 2/20\n",
      "24s - loss: 0.1007 - val_loss: 0.0984\n",
      "Epoch 3/20\n",
      "24s - loss: 0.0992 - val_loss: 0.0973\n",
      "Epoch 4/20\n",
      "24s - loss: 0.0983 - val_loss: 0.0966\n",
      "Epoch 5/20\n",
      "24s - loss: 0.0978 - val_loss: 0.0962\n",
      "Epoch 6/20\n",
      "24s - loss: 0.0974 - val_loss: 0.0959\n",
      "Epoch 7/20\n",
      "24s - loss: 0.0971 - val_loss: 0.0956\n",
      "Epoch 8/20\n",
      "24s - loss: 0.0969 - val_loss: 0.0955\n",
      "Epoch 9/20\n",
      "24s - loss: 0.0967 - val_loss: 0.0953\n",
      "Epoch 10/20\n",
      "24s - loss: 0.0965 - val_loss: 0.0952\n",
      "Epoch 11/20\n",
      "24s - loss: 0.0964 - val_loss: 0.0951\n",
      "Epoch 12/20\n",
      "24s - loss: 0.0963 - val_loss: 0.0950\n",
      "Epoch 13/20\n",
      "24s - loss: 0.0961 - val_loss: 0.0949\n",
      "Epoch 14/20\n",
      "23s - loss: 0.0961 - val_loss: 0.0948\n",
      "Epoch 15/20\n",
      "24s - loss: 0.0960 - val_loss: 0.0947\n",
      "Epoch 16/20\n",
      "24s - loss: 0.0959 - val_loss: 0.0947\n",
      "Epoch 17/20\n",
      "24s - loss: 0.0959 - val_loss: 0.0946\n",
      "Epoch 18/20\n",
      "24s - loss: 0.0958 - val_loss: 0.0946\n",
      "Epoch 19/20\n",
      "24s - loss: 0.0957 - val_loss: 0.0946\n",
      "Epoch 20/20\n",
      "24s - loss: 0.0957 - val_loss: 0.0945\n",
      "-0.296620335718\n",
      "\n",
      "\n",
      "Starting CV for 256 20 sigmoid adadelta\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "21s - loss: 0.1019 - val_loss: 0.0957\n",
      "Epoch 2/20\n",
      "21s - loss: 0.0961 - val_loss: 0.0950\n",
      "Epoch 3/20\n",
      "21s - loss: 0.0954 - val_loss: 0.0941\n",
      "Epoch 4/20\n",
      "21s - loss: 0.0951 - val_loss: 0.0939\n",
      "Epoch 5/20\n",
      "21s - loss: 0.0950 - val_loss: 0.0940\n",
      "Epoch 6/20\n",
      "21s - loss: 0.0949 - val_loss: 0.0936\n",
      "Epoch 7/20\n",
      "21s - loss: 0.0948 - val_loss: 0.0935\n",
      "Epoch 8/20\n",
      "21s - loss: 0.0947 - val_loss: 0.0942\n",
      "Epoch 9/20\n",
      "21s - loss: 0.0946 - val_loss: 0.0933\n",
      "Epoch 10/20\n",
      "21s - loss: 0.0945 - val_loss: 0.0933\n",
      "Epoch 11/20\n",
      "20s - loss: 0.0944 - val_loss: 0.0938\n",
      "Epoch 12/20\n",
      "21s - loss: 0.0944 - val_loss: 0.0932\n",
      "Epoch 13/20\n",
      "21s - loss: 0.0943 - val_loss: 0.0930\n",
      "Epoch 14/20\n",
      "21s - loss: 0.0943 - val_loss: 0.0932\n",
      "Epoch 15/20\n",
      "21s - loss: 0.0942 - val_loss: 0.0929\n",
      "Epoch 16/20\n",
      "21s - loss: 0.0942 - val_loss: 0.0929\n",
      "Epoch 17/20\n",
      "21s - loss: 0.0941 - val_loss: 0.0934\n",
      "Epoch 18/20\n",
      "21s - loss: 0.0941 - val_loss: 0.0928\n",
      "Epoch 19/20\n",
      "21s - loss: 0.0941 - val_loss: 0.0928\n",
      "Epoch 20/20\n",
      "21s - loss: 0.0940 - val_loss: 0.0927\n",
      "-0.293681451918\n",
      "\n",
      "\n",
      "Starting CV for 256 20 sigmoid adamax\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "25s - loss: 0.0997 - val_loss: 0.0947\n",
      "Epoch 2/20\n",
      "24s - loss: 0.0954 - val_loss: 0.0943\n",
      "Epoch 3/20\n",
      "24s - loss: 0.0950 - val_loss: 0.0937\n",
      "Epoch 4/20\n",
      "24s - loss: 0.0948 - val_loss: 0.0935\n",
      "Epoch 5/20\n",
      "25s - loss: 0.0946 - val_loss: 0.0932\n",
      "Epoch 6/20\n",
      "24s - loss: 0.0945 - val_loss: 0.0930\n",
      "Epoch 7/20\n",
      "24s - loss: 0.0944 - val_loss: 0.0929\n",
      "Epoch 8/20\n",
      "24s - loss: 0.0943 - val_loss: 0.0929\n",
      "Epoch 9/20\n",
      "24s - loss: 0.0942 - val_loss: 0.0929\n",
      "Epoch 10/20\n",
      "29s - loss: 0.0941 - val_loss: 0.0930\n",
      "Epoch 11/20\n",
      "25s - loss: 0.0940 - val_loss: 0.0932\n",
      "-0.294463030855\n",
      "\n",
      "\n",
      "Starting CV for 256 20 sigmoid nadam\n",
      "Train on 6397531 samples, validate on 1599383 samples\n",
      "Epoch 1/20\n",
      "26s - loss: 0.0977 - val_loss: 0.0946\n",
      "Epoch 2/20\n",
      "28s - loss: 0.0949 - val_loss: 0.0940\n",
      "Epoch 3/20\n",
      "28s - loss: 0.0945 - val_loss: 0.0930\n",
      "Epoch 4/20\n",
      "25s - loss: 0.0943 - val_loss: 0.0930\n",
      "Epoch 5/20\n",
      "25s - loss: 0.0941 - val_loss: 0.0925\n",
      "Epoch 6/20\n",
      "25s - loss: 0.0939 - val_loss: 0.0922\n",
      "Epoch 7/20\n",
      "25s - loss: 0.0937 - val_loss: 0.0927\n",
      "Epoch 8/20\n",
      "26s - loss: 0.0936 - val_loss: 0.0927\n",
      "Epoch 9/20\n",
      "25s - loss: 0.0935 - val_loss: 0.0923\n",
      "-0.292977698099\n"
     ]
    }
   ],
   "source": [
    "grid_scores = {}\n",
    "for batch_size in param_grid[0]['batch_size']:\n",
    "    for nb_epoch in param_grid[0]['nb_epoch']:\n",
    "        for hidden_activation in param_grid[0]['hidden_activation']:\n",
    "            for optimizer in param_grid[0]['optimizer']:\n",
    "                key = \" \".join([str(batch_size), str(nb_epoch), str(hidden_activation), str(optimizer)])\n",
    "                print(\"\\n\\nStarting CV for \" + key)\n",
    "                clf = KerasClassifier(build_fn, batch_size=batch_size, \n",
    "                                      nb_epoch=nb_epoch, hidden_activation=hidden_activation, \n",
    "                                      optimizer=optimizer, \n",
    "                                      callbacks=[EarlyStopping(monitor='val_loss', patience=2)], \n",
    "                                      validation_split=0.2, verbose=2)\n",
    "                clf.fit(X_train, y_train)\n",
    "                rmse = my_custom_scorer_neural(clf, X_val, y_val)\n",
    "                grid_scores[key] = rmse\n",
    "                print rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'128 20 relu adadelta': -0.29385568604943346,\n",
       " '128 20 relu adagrad': -0.29532124753027389,\n",
       " '128 20 relu adamax': -0.29455240879803946,\n",
       " '128 20 relu nadam': -0.29413420346303876,\n",
       " '128 20 sigmoid adadelta': -0.29343301227231011,\n",
       " '128 20 sigmoid adagrad': -0.29651971405943789,\n",
       " '128 20 sigmoid adamax': -0.29261940864883129,\n",
       " '128 20 sigmoid nadam': -0.2932575636638457,\n",
       " '256 20 relu adadelta': -0.29414278337656485,\n",
       " '256 20 relu adagrad': -0.29534116043652392,\n",
       " '256 20 relu adamax': -0.29572626411069064,\n",
       " '256 20 relu nadam': -0.29277247137921925,\n",
       " '256 20 sigmoid adadelta': -0.29368145191823447,\n",
       " '256 20 sigmoid adagrad': -0.29662033571804203,\n",
       " '256 20 sigmoid adamax': -0.29446303085456554,\n",
       " '256 20 sigmoid nadam': -0.29297769809882479}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/6(dict).pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_scores, 'Pickles/Condensed_Basic+Temporal+Recency/GridSearches/NNs/6(dict).pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
