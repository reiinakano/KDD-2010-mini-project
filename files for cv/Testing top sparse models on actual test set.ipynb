{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8483920x217691 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 154318299 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = joblib.load('Pickles/Sparse_Basic+Temporal+Recency/train.pkl')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8483920L,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = joblib.load('Pickles/labels.pkl')\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<508912x217691 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 9340125 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = joblib.load('Pickles/Sparse_Basic+Temporal+Recency/test.pkl')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LR penalty L2 C10\n",
    "lr = LogisticRegression(C=10., random_state=0, n_jobs=-1, verbose=10)\n",
    "scaler = StandardScaler(with_mean=False, copy=False)\n",
    "clf = Pipeline([('scaler', scaler), ('logreg', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Argel\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:924: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=False, with_mean=False, with_std=True)), ('logreg', LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=10, warm_start=False))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickles/Sparse_Basic+Temporal+Recency/TrainedCLFs/LogReg/L2C10/model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'Pickles/Sparse_Basic+Temporal+Recency/TrainedCLFs/LogReg/L2C10/model.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.148954  ,  0.851046  ],\n",
       "       [ 0.1383367 ,  0.8616633 ],\n",
       "       [ 0.00929406,  0.99070594],\n",
       "       ..., \n",
       "       [ 0.24137058,  0.75862942],\n",
       "       [ 0.04771305,  0.95228695],\n",
       "       [ 0.03362875,  0.96637125]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = clf.predict_proba(X_test)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484686 24226\n"
     ]
    }
   ],
   "source": [
    "ones = []\n",
    "zeros = []\n",
    "for zero_prob, one_prob in probas:\n",
    "    if one_prob > zero_prob:\n",
    "        ones.append(one_prob)\n",
    "    else:\n",
    "        zeros.append(one_prob)\n",
    "        \n",
    "print len(ones), len(zeros)\n",
    "\n",
    "import csv\n",
    "with open('Pickles/Sparse_Basic+Temporal+Recency/TrainedCLFs/LogReg/L2C10/algebra_2008_2009_submission.txt', 'wb') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "    spamwriter.writerow(['Row', 'Correct First Attempt'])\n",
    "    for index, (zero_prob, one_prob) in enumerate(probas):\n",
    "        spamwriter.writerow([index+1, float(one_prob)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8483920x217691 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 154318299 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = joblib.load('Pickles/Sparse_Basic+Temporal+Recency/train.pkl')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8483920L,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = joblib.load('Pickles/labels.pkl')\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<508912x217691 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 9340125 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = joblib.load('Pickles/Sparse_Basic+Temporal+Recency/test.pkl')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LR penalty L2 C1\n",
    "lr = LogisticRegression(C=1., random_state=0, n_jobs=-1, verbose=10)\n",
    "scaler = StandardScaler(with_mean=False, copy=False)\n",
    "clf = Pipeline([('scaler', scaler), ('logreg', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=False, with_mean=False, with_std=True)), ('logreg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=10, warm_start=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickles/Sparse_Basic+Temporal+Recency/TrainedCLFs/LogReg/L2C1/model.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'Pickles/Sparse_Basic+Temporal+Recency/TrainedCLFs/LogReg/L2C1/model.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14916571,  0.85083429],\n",
       "       [ 0.13860786,  0.86139214],\n",
       "       [ 0.0070964 ,  0.9929036 ],\n",
       "       ..., \n",
       "       [ 0.24340679,  0.75659321],\n",
       "       [ 0.04771555,  0.95228445],\n",
       "       [ 0.03381186,  0.96618814]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = clf.predict_proba(X_test)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484650 24262\n"
     ]
    }
   ],
   "source": [
    "ones = []\n",
    "zeros = []\n",
    "for zero_prob, one_prob in probas:\n",
    "    if one_prob > zero_prob:\n",
    "        ones.append(one_prob)\n",
    "    else:\n",
    "        zeros.append(one_prob)\n",
    "        \n",
    "print len(ones), len(zeros)\n",
    "\n",
    "import csv\n",
    "with open('Pickles/Sparse_Basic+Temporal+Recency/TrainedCLFs/LogReg/L2C1/algebra_2008_2009_submission.txt', 'wb') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "    spamwriter.writerow(['Row', 'Correct First Attempt'])\n",
    "    for index, (zero_prob, one_prob) in enumerate(probas):\n",
    "        spamwriter.writerow([index+1, float(one_prob)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LR3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8483920x217691 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 154318299 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = joblib.load('Pickles/Sparse_Basic+Temporal+Recency/train.pkl')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8483920L,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = joblib.load('Pickles/labels.pkl')\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<508912x217691 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 9340125 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = joblib.load('Pickles/Sparse_Basic+Temporal+Recency/test.pkl')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LR penalty L1 C10\n",
    "lr = LogisticRegression(C=0.001, random_state=0, n_jobs=-1, verbose=10, penalty='l1')\n",
    "scaler = StandardScaler(with_mean=False, copy=False)\n",
    "clf = Pipeline([('scaler', scaler), ('logreg', lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=False, with_mean=False, with_std=True)), ('logreg', LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l1', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=10, warm_start=False))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickles/Sparse_Basic+Temporal+Recency/TrainedCLFs/LogReg/L1C001/model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'Pickles/Sparse_Basic+Temporal+Recency/TrainedCLFs/LogReg/L1C001/model.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14287717,  0.85712283],\n",
       "       [ 0.13367135,  0.86632865],\n",
       "       [ 0.00593404,  0.99406596],\n",
       "       ..., \n",
       "       [ 0.27948154,  0.72051846],\n",
       "       [ 0.05949028,  0.94050972],\n",
       "       [ 0.04949227,  0.95050773]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas = clf.predict_proba(X_test)\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486814 22098\n"
     ]
    }
   ],
   "source": [
    "ones = []\n",
    "zeros = []\n",
    "for zero_prob, one_prob in probas:\n",
    "    if one_prob > zero_prob:\n",
    "        ones.append(one_prob)\n",
    "    else:\n",
    "        zeros.append(one_prob)\n",
    "        \n",
    "print len(ones), len(zeros)\n",
    "\n",
    "import csv\n",
    "with open('Pickles/Sparse_Basic+Temporal+Recency/TrainedCLFs/LogReg/L1C001/algebra_2008_2009_submission.txt', 'wb') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter='\\t')\n",
    "    spamwriter.writerow(['Row', 'Correct First Attempt'])\n",
    "    for index, (zero_prob, one_prob) in enumerate(probas):\n",
    "        spamwriter.writerow([index+1, float(one_prob)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
